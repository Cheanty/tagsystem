
## 文本数据标注系统

### 基本要求

使用B/S架构设计一个软件，实现对非结构化文本数据的标注：
- **分词和关键词标注：** 将连续的文本序列分解为有意义的词语单元  LAC
- **命名实体标注：** 文本中具有特殊命名的实体名词 LAC
- **关系标注：** 命名实体之间的关系
- **情感标注(正面、负面、中性)：** 文本的情感倾向 SNOWNLP
- **意图标注：** 文本中潜在的意图与目的
- **语义标注：** 对文本的语义层次进行分析和理解，表示文本的深层含义
- **事件标注（主体、客体、时间、地点、原因、结果）：** 对文本中描述的事件进行结构化标注

最后实现原始文本、标注信息、统计信息的可视化

### 选做要求

- 调研自然语言处理的最新技术以及相关论文、设计并实现一种改进的自动标注算法
- 在只能标注的基础上、设计人工校正和反馈机制，提高智能标注的准确性
- 美观的可视化界面、良好的数据库设计

### 进度安排

| 完成度 | 任务          | 时间      |
| --- | ----------- | ------- |
| x   | 集中讲座见面会     | 第6周     |
| x   | 分组名单提交      | 第7周     |
|     | 查阅资料、方案论证   | 第8~10周  |
|     | 中期报告撰写与提交   | 第11周    |
|     | 软件设计与调试     | 第12~17周 |
|     | 软件演示与验收     | 第18周    |
|     | 课程设计报告撰写与提交 | 第19周    |

## 初步设想

### 基本框架搭建

**语言：** python，语法简单，同时有大量的现成分词框架和调用包，同时深度学习环境成熟

**Web框架：** flask，python的轻量级Web框架，语法配置简单，同时轻量方便部署在容器或者服务器中

**网关：** apache，稳定简单，比nginx配置简单且稳定

**其他工具：** git、mysql

### 分词模型选择

#### 1. 分词和关键词标注

- **LAC（Lexical Analysis of Chinese）**：支持中文分词和关键词提取。
- **结巴分词（jieba）**：常用的中文分词工具，简单易用。
- **TF-IDF**：用于关键词提取的经典算法。
- **SNOWNLP**

#### 2. 命名实体标注（NER）

- **BERT**：通过微调，可以实现高效的命名实体识别。
- **SpaCy**：具有内置的NER功能，支持多种语言。
- **Flair**：一个基于PyTorch的NLP库，支持NER任务。
- **LAC**：也支持中文的命名实体识别。

#### 3. 关系标注

- **OpenIE（Open Information Extraction）**：用于提取文本中的关系。
- **关系分类模型（如基于BERT的模型）**：可以训练关系分类任务。
- **Spacy**

#### 4. 情感标注

- **TextBlob**：简单的情感分析工具，适合英文文本。
- **VADER**：专门针对社交媒体文本的情感分析工具。
- **BERT**：可以通过微调用于情感分析任务。
- **SNOWNLP**

#### 5. 意图标注

- **Rasa**：开源对话系统框架，支持意图识别。
- **BERT**：可以通过微调用于意图识别任务。

#### 6. 语义标注

- **BERT**和**GPT**：可用于句子嵌入和语义理解。
- **Sentence-BERT**：基于BERT的句子嵌入模型，适合语义相似度计算。

#### 7. 事件标注

- **事件抽取模型**：通常基于深度学习的序列标注模型（如LSTM、BERT等）进行训练，以识别事件的不同要素。
- **基于规则的方法**：使用模式匹配和模板识别来标注事件。

#### 综合方案

同时选择能够支持中文分词要求的

为了实现一个全面的文本数据标注系统，可能需要结合多个模型和工具。可以使用像**SpaCy**或**Hugging Face Transformers**等库，整合多种NLP功能，便于实现分词、NER、情感分析等功能。


### 数据库设计

### 界面设计

### 后端实现

| 名称                                | 描述                                              |
| --------------------------------- | ----------------------------------------------- |
| Tokenization                      | 将文本分割成单词、标点符号等。                                 |
| Part-of-speech (POS) Tagging      | 给标记分配词性，如动词或名词。                                 |
| Dependency Parsing                | 分配句法依存标签，描述个别标记之间的关系，如主语或宾语。                    |
| Lemmatization                     | 分配单词的基本形式。例如，“was”的基本形式是“be”，“rats”的基本形式是“rat”。 |
| Sentence Boundary Detection (SBD) | 查找和分割单个句子。                                      |
| Named Entity Recognition (NER)    | 对命名的“现实世界”对象进行标记，如人物、公司或地点。                     |
| Entity Linking (EL)               | 将文本实体与知识库中的唯一标识符进行消岐。                           |
| Similarity                        | 比较单词、文本片段和文档之间的相似程度。                            |
| Text Classification               | 为整个文档或文档的部分分配类别或标签。                             |
| Rule-based Matching               | 根据其文本和语言注释查找标记序列，类似于正则表达式。                      |
| Training                          | 更新和改进统计模型的预测能力。                                 |
| Serialization                     | 将对象保存到文件或字节字符串中。                                |
